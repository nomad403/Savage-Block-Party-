"use client";

import { useEffect, useState, useRef, useCallback } from 'react';

// Imports avec gestion d'erreur pour √©viter les erreurs de runtime
let analyze: any, guess: any, Meyda: any;

try {
  const beatDetector = require('web-audio-beat-detector');
  analyze = beatDetector.analyze;
  guess = beatDetector.guess;
} catch (error) {
  console.warn('web-audio-beat-detector non disponible:', error);
}

try {
  Meyda = require('meyda');
} catch (error) {
  console.warn('Meyda non disponible:', error);
}

interface BPMAnalysis {
  bpm: number;
  offset: number;
  tempo: number;
}

interface AudioFeatures {
  rms: number;
  spectralCentroid: number;
  spectralRolloff: number;
  spectralFlux: number;
  spectralSpread: number;
}

interface BPMDetectionResult {
  bpm: number | null;
  audioFeatures: AudioFeatures | null;
  isAnalyzing: boolean;
  error: string | null;
}

export function useBPMDetection() {
  const [result, setResult] = useState<BPMDetectionResult>({
    bpm: null,
    audioFeatures: null,
    isAnalyzing: false,
    error: null
  });

  // üî• NOUVEAU : √âtat pour d√©sactiver Meyda si elle cause des erreurs
  const [meydaDisabled, setMeydaDisabled] = useState(false);
  const [meydaErrorCount, setMeydaErrorCount] = useState(0);
  const maxMeydaErrors = 5; // D√©sactiver Meyda apr√®s 5 erreurs cons√©cutives

  const audioContextRef = useRef<AudioContext | null>(null);
  const analyzerRef = useRef<any>(null);
  const meydaAnalyzerRef = useRef<any>(null);
  const sourceRef = useRef<MediaElementAudioSourceNode | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  // üî• SOLUTION STABLE CONTEXT7 : Cr√©er l'AudioContext uniquement √† la premi√®re interaction utilisateur
  const getOrCreateAudioContext = useCallback(async () => {
    try {
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
        console.log('üéß AudioContext cr√©√©');
      }

      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
        console.log('üéß AudioContext relanc√© par interaction');
      }

      return audioContextRef.current;
    } catch (error) {
      console.error('Erreur cr√©ation/reprise AudioContext:', error);
      setResult(prev => ({ ...prev, error: 'Impossible d\'initialiser l\'AudioContext' }));
      return null;
    }
  }, []);

  // Fonction pour forcer la reprise de l'AudioContext (expos√©e pour usage externe)
  const resumeAudioContext = useCallback(async () => {
    if (!audioContextRef.current) return false;
    
    try {
      if (audioContextRef.current.state === 'suspended') {
        console.log('üîÑ Reprise forc√©e de l\'AudioContext...');
        await audioContextRef.current.resume();
        console.log('‚úÖ AudioContext repris avec succ√®s');
        return true;
      } else if (audioContextRef.current.state === 'running') {
        console.log('‚úÖ AudioContext d√©j√† actif');
        return true;
      } else {
        console.warn('‚ö†Ô∏è AudioContext dans un √©tat inattendu:', audioContextRef.current.state);
        return false;
      }
    } catch (error) {
      console.error('‚ùå Erreur lors de la reprise de l\'AudioContext:', error);
      return false;
    }
  }, []);

  // Analyser le BPM d'un AudioBuffer
  const analyzeBPM = useCallback(async (audioBuffer: AudioBuffer): Promise<BPMAnalysis | null> => {
    try {
      if (!guess) {
        console.warn('web-audio-beat-detector non disponible, analyse BPM d√©sactiv√©e');
        return null;
      }

      setResult(prev => ({ ...prev, isAnalyzing: true, error: null }));
      
      const analysis = await guess(audioBuffer);
      console.log('üéµ BPM d√©tect√©:', analysis);
      
      setResult(prev => ({ 
        ...prev, 
        bpm: analysis.bpm,
        isAnalyzing: false 
      }));
      
      return analysis;
    } catch (error) {
      console.error('Erreur analyse BPM:', error);
      setResult(prev => ({ 
        ...prev, 
        error: 'Erreur lors de l\'analyse BPM',
        isAnalyzing: false 
      }));
      return null;
    }
  }, []);

  // Configurer Meyda pour l'analyse en temps r√©el
  const setupMeydaAnalyzer = useCallback((audioElement: HTMLAudioElement) => {
    if (!audioContextRef.current) return;

    try {
      // Cr√©er le source node depuis l'√©l√©ment audio
      const source = audioContextRef.current.createMediaElementSource(audioElement);
      sourceRef.current = source;
      
      // Connecter au destination pour entendre l'audio
      source.connect(audioContextRef.current.destination);

      // Cr√©er l'analyseur Meyda
      const meydaAnalyzer = Meyda.createMeydaAnalyzer({
        audioContext: audioContextRef.current,
        source: source,
        bufferSize: 512,
        featureExtractors: [
          'rms',
          'spectralCentroid', 
          'spectralRolloff',
          'spectralFlux',
          'spectralSpread'
        ],
        callback: (features: any) => {
          const audioFeatures: AudioFeatures = {
            rms: features.rms || 0,
            spectralCentroid: features.spectralCentroid || 0,
            spectralRolloff: features.spectralRolloff || 0,
            spectralFlux: features.spectralFlux || 0,
            spectralSpread: features.spectralSpread || 0
          };

          setResult(prev => ({ 
            ...prev, 
            audioFeatures 
          }));

          // D√©clencher un √©v√©nement personnalis√© pour les effets visuels
          window.dispatchEvent(new CustomEvent('audioFeatures', { 
            detail: audioFeatures 
          }));
        }
      });

      meydaAnalyzerRef.current = meydaAnalyzer;
      meydaAnalyzer.start();
      
      console.log('üéõÔ∏è Meyda analyzer d√©marr√©');
    } catch (error) {
      console.error('Erreur configuration Meyda:', error);
      setResult(prev => ({ 
        ...prev, 
        error: 'Erreur configuration analyseur audio' 
      }));
    }
  }, []);

  // üî• NOUVEAU : Syst√®me de fallback pour g√©n√©rer des features audio simul√©es
  const generateFallbackAudioFeatures = useCallback(() => {
    // G√©n√©rer des features audio simul√©es bas√©es sur le temps et des patterns
    const now = Date.now();
    const timeFactor = (now % 10000) / 10000; // Cycle de 10 secondes
    
    // Simuler des variations d'intensit√© audio
    const baseIntensity = 0.3 + 0.2 * Math.sin(timeFactor * Math.PI * 2);
    const beatFactor = Math.sin(timeFactor * Math.PI * 8) * 0.3; // 8 beats par cycle
    const randomFactor = (Math.random() - 0.5) * 0.1; // Variation al√©atoire
    
    const intensity = Math.max(0, Math.min(1, baseIntensity + beatFactor + randomFactor));
    
    const audioFeatures: AudioFeatures = {
      rms: intensity * 0.15, // RMS simul√©
      spectralCentroid: intensity * 0.8, // Centro√Øde spectral simul√©
      spectralRolloff: intensity * 0.6, // Rolloff simul√©
      spectralFlux: intensity * 0.4, // Flux spectral simul√©
      spectralSpread: intensity * 0.3, // Spread simul√©
    };
    
    setResult(prev => ({
      ...prev,
      audioFeatures,
      isAnalyzing: true
    }));

    // Dispatcher l'√©v√©nement pour les autres composants
    window.dispatchEvent(new CustomEvent('audioFeatures', { detail: audioFeatures }));
  }, []);

  // üî• CORRECTION : Analyser le vrai flux audio connect√© √† l'AudioContext
  const analyzeSoundCloudAudio = useCallback(async (audioElement: HTMLAudioElement) => {
    const ctx = audioContextRef.current;
    if (!ctx) {
      console.warn('‚ùå AudioContext non disponible');
      return;
    }

    if (!Meyda) {
      console.warn('‚ùå Meyda non disponible');
      return;
    }

    try {
      // üî• CRUCIAL : Cr√©er la source depuis l'√©l√©ment audio connect√©
      const source = ctx.createMediaElementSource(audioElement);
      
      // üî• CRUCIAL : Cr√©er l'analyseur Meyda avec le vrai flux
      const analyzer = Meyda.createMeydaAnalyzer({
        audioContext: ctx,
        source,
        bufferSize: 512, // Buffer plus petit pour plus de r√©activit√©
        featureExtractors: ["rms", "spectralCentroid", "spectralFlux"],
        callback: (features) => {
          if (!features) return;
          
          // üî• CRUCIAL : Logs pour v√©rifier que Meyda re√ßoit des donn√©es
          console.log("üéß Frame:", features.rms?.toFixed(3), features.spectralFlux?.toFixed(3));
          
          const audioFeatures: AudioFeatures = {
            rms: features.rms || 0,
            spectralCentroid: features.spectralCentroid || 0,
            spectralRolloff: 0,
            spectralFlux: features.spectralFlux || 0,
            spectralSpread: 0,
          };
          
          setResult(prev => ({
            ...prev,
            audioFeatures,
            isAnalyzing: true
          }));

          // Dispatcher l'√©v√©nement pour les autres composants
          window.dispatchEvent(new CustomEvent('audioFeatures', { detail: audioFeatures }));
        },
      });

      analyzer.start();
      meydaAnalyzerRef.current = analyzer;
      console.log('‚úÖ Meyda d√©marr√© sur le vrai flux audio');
      
    } catch (error) {
      console.error('‚ùå Erreur analyse audio:', error);
    }
  }, []);

  // üî• SOLUTION STABLE CONTEXT7 : Heartbeat pour √©viter les suspensions automatiques
  useEffect(() => {
    if (!audioContextRef.current) return;
    const ctx = audioContextRef.current;

    const heartbeat = setInterval(async () => {
      if (ctx.state === 'suspended') {
        try {
          await ctx.resume();
          console.log('üîÑ AudioContext heartbeat ‚Üí resumed');
        } catch (error) {
          console.warn('‚ö†Ô∏è √âchec heartbeat AudioContext:', error);
        }
      }
    }, 3000);

    return () => clearInterval(heartbeat);
  }, []);

  // üî• NOUVEAU : Surveiller les erreurs Meyda et d√©sactiver si n√©cessaire
  useEffect(() => {
    if (meydaErrorCount >= maxMeydaErrors && !meydaDisabled) {
      console.warn(`‚ö†Ô∏è Meyda d√©sactiv√©e apr√®s ${maxMeydaErrors} erreurs cons√©cutives`);
      setMeydaDisabled(true);
      
      // Arr√™ter l'analyseur Meyda actuel
      if (meydaAnalyzerRef.current) {
        try {
          meydaAnalyzerRef.current.stop();
          meydaAnalyzerRef.current = null;
        } catch (error) {
          console.warn('Erreur arr√™t analyseur Meyda:', error);
        }
      }
      
      // D√©marrer le syst√®me de fallback
      const fallbackInterval = setInterval(generateFallbackAudioFeatures, 200);
      
      return () => clearInterval(fallbackInterval);
    }
  }, [meydaErrorCount, maxMeydaErrors, meydaDisabled, generateFallbackAudioFeatures]);

  // Nettoyer les ressources
  const cleanup = useCallback(() => {
    if (meydaAnalyzerRef.current) {
      meydaAnalyzerRef.current.stop();
      meydaAnalyzerRef.current = null;
    }
    
    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
  }, []);

  // Cleanup au d√©montage
  useEffect(() => {
    return cleanup;
  }, [cleanup]);

  return {
    ...result,
    analyzeSoundCloudAudio,
    analyzeBPM,
    cleanup,
    resumeAudioContext, // Exposer la fonction de reprise pour usage externe
    audioContextRef, // Exposer la r√©f√©rence pour surveillance externe
    meydaDisabled, // Exposer l'√©tat de Meyda pour debugging
    meydaErrorCount // Exposer le compteur d'erreurs pour debugging
  };
}
